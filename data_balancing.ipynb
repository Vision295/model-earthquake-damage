{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37bca214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train_values.csv\")\n",
    "\n",
    "categorical_columns = [\n",
    "     \"roof_type               \",\n",
    "     \"land_surface_condition  \",\n",
    "     \"legal_ownership_status  \",\n",
    "     \"other_floor_type        \",\n",
    "     \"position                \",\n",
    "     \"foundation_type         \",\n",
    "     \"ground_floor_type       \",\n",
    "     \"count_floors_pre_eq     \",\n",
    "     \"count_families          \",\n",
    "     \"plan_configuration      \" \n",
    "]\n",
    "\n",
    "bool_columns = [\n",
    "      \"has_superstructure_adobe_mud                \",\n",
    "      \"has_superstructure_bamboo                   \",\n",
    "      \"has_secondary_use_rental                    \", \n",
    "      \"has_secondary_use_hotel                     \", \n",
    "      \"has_secondary_use                           \",  \n",
    "      \"has_secondary_use_agriculture               \", \n",
    "      \"has_superstructure_other                    \", \n",
    "      \"has_superstructure_rc_engineered            \",  \n",
    "      \"has_superstructure_rc_non_engineered        \",  \n",
    "      \"has_superstructure_cement_mortar_stone      \",  \n",
    "      \"has_superstructure_timber                   \",  \n",
    "      \"has_superstructure_cement_mortar_brick      \",  \n",
    "      \"has_superstructure_mud_mortar_brick         \",  \n",
    "      \"has_superstructure_mud_mortar_stone         \",  \n",
    "      \"has_superstructure_stone_flag               \",  \n",
    "      \"has_secondary_use_institution               \",  \n",
    "      \"has_secondary_use_health_post               \",  \n",
    "      \"has_secondary_use_other                     \",  \n",
    "      \"has_secondary_use_use_police                \",  \n",
    "      \"has_secondary_use_gov_office                \",  \n",
    "      \"has_secondary_use_school                    \",  \n",
    "      \"has_secondary_use_industry                  \"  \n",
    "]\n",
    "categorical_columns = list(map(lambda x: x.strip(), categorical_columns))\n",
    "bool_columns = list(map(lambda x: x.strip(), bool_columns))\n",
    "\n",
    "df[categorical_columns] = df[categorical_columns].astype(\"category\")\n",
    "df[bool_columns] = df[bool_columns].astype(\"bool\")\n",
    "\n",
    "def print_style(msg:str):\n",
    "      print(\"\\n----------------------------\")\n",
    "      print(msg)\n",
    "      print(\"----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb6ffc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------\n",
      "shape of data set : (260601, 39)\n",
      "----------------------------\n",
      "\n",
      "\n",
      "----------------------------\n",
      "dtypes of data set : building_id                                  int64\n",
      "geo_level_1_id                               int64\n",
      "geo_level_2_id                               int64\n",
      "geo_level_3_id                               int64\n",
      "count_floors_pre_eq                       category\n",
      "age                                          int64\n",
      "area_percentage                              int64\n",
      "height_percentage                            int64\n",
      "land_surface_condition                    category\n",
      "foundation_type                           category\n",
      "roof_type                                 category\n",
      "ground_floor_type                         category\n",
      "other_floor_type                          category\n",
      "position                                  category\n",
      "plan_configuration                        category\n",
      "has_superstructure_adobe_mud                  bool\n",
      "has_superstructure_mud_mortar_stone           bool\n",
      "has_superstructure_stone_flag                 bool\n",
      "has_superstructure_cement_mortar_stone        bool\n",
      "has_superstructure_mud_mortar_brick           bool\n",
      "has_superstructure_cement_mortar_brick        bool\n",
      "has_superstructure_timber                     bool\n",
      "has_superstructure_bamboo                     bool\n",
      "has_superstructure_rc_non_engineered          bool\n",
      "has_superstructure_rc_engineered              bool\n",
      "has_superstructure_other                      bool\n",
      "legal_ownership_status                    category\n",
      "count_families                            category\n",
      "has_secondary_use                             bool\n",
      "has_secondary_use_agriculture                 bool\n",
      "has_secondary_use_hotel                       bool\n",
      "has_secondary_use_rental                      bool\n",
      "has_secondary_use_institution                 bool\n",
      "has_secondary_use_school                      bool\n",
      "has_secondary_use_industry                    bool\n",
      "has_secondary_use_health_post                 bool\n",
      "has_secondary_use_gov_office                  bool\n",
      "has_secondary_use_use_police                  bool\n",
      "has_secondary_use_other                       bool\n",
      "dtype: object\n",
      "----------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260601 entries, 0 to 260600\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                  Non-Null Count   Dtype   \n",
      "---  ------                                  --------------   -----   \n",
      " 0   building_id                             260601 non-null  int64   \n",
      " 1   geo_level_1_id                          260601 non-null  int64   \n",
      " 2   geo_level_2_id                          260601 non-null  int64   \n",
      " 3   geo_level_3_id                          260601 non-null  int64   \n",
      " 4   count_floors_pre_eq                     260601 non-null  category\n",
      " 5   age                                     260601 non-null  int64   \n",
      " 6   area_percentage                         260601 non-null  int64   \n",
      " 7   height_percentage                       260601 non-null  int64   \n",
      " 8   land_surface_condition                  260601 non-null  category\n",
      " 9   foundation_type                         260601 non-null  category\n",
      " 10  roof_type                               260601 non-null  category\n",
      " 11  ground_floor_type                       260601 non-null  category\n",
      " 12  other_floor_type                        260601 non-null  category\n",
      " 13  position                                260601 non-null  category\n",
      " 14  plan_configuration                      260601 non-null  category\n",
      " 15  has_superstructure_adobe_mud            260601 non-null  bool    \n",
      " 16  has_superstructure_mud_mortar_stone     260601 non-null  bool    \n",
      " 17  has_superstructure_stone_flag           260601 non-null  bool    \n",
      " 18  has_superstructure_cement_mortar_stone  260601 non-null  bool    \n",
      " 19  has_superstructure_mud_mortar_brick     260601 non-null  bool    \n",
      " 20  has_superstructure_cement_mortar_brick  260601 non-null  bool    \n",
      " 21  has_superstructure_timber               260601 non-null  bool    \n",
      " 22  has_superstructure_bamboo               260601 non-null  bool    \n",
      " 23  has_superstructure_rc_non_engineered    260601 non-null  bool    \n",
      " 24  has_superstructure_rc_engineered        260601 non-null  bool    \n",
      " 25  has_superstructure_other                260601 non-null  bool    \n",
      " 26  legal_ownership_status                  260601 non-null  category\n",
      " 27  count_families                          260601 non-null  category\n",
      " 28  has_secondary_use                       260601 non-null  bool    \n",
      " 29  has_secondary_use_agriculture           260601 non-null  bool    \n",
      " 30  has_secondary_use_hotel                 260601 non-null  bool    \n",
      " 31  has_secondary_use_rental                260601 non-null  bool    \n",
      " 32  has_secondary_use_institution           260601 non-null  bool    \n",
      " 33  has_secondary_use_school                260601 non-null  bool    \n",
      " 34  has_secondary_use_industry              260601 non-null  bool    \n",
      " 35  has_secondary_use_health_post           260601 non-null  bool    \n",
      " 36  has_secondary_use_gov_office            260601 non-null  bool    \n",
      " 37  has_secondary_use_use_police            260601 non-null  bool    \n",
      " 38  has_secondary_use_other                 260601 non-null  bool    \n",
      "dtypes: bool(22), category(10), int64(7)\n",
      "memory usage: 21.9 MB\n",
      "\n",
      "----------------------------\n",
      "info of data set : None\n",
      "----------------------------\n",
      "\n",
      "\n",
      "----------------------------\n",
      "Null values in dataset : building_id                               0\n",
      "geo_level_1_id                            0\n",
      "geo_level_2_id                            0\n",
      "geo_level_3_id                            0\n",
      "count_floors_pre_eq                       0\n",
      "age                                       0\n",
      "area_percentage                           0\n",
      "height_percentage                         0\n",
      "land_surface_condition                    0\n",
      "foundation_type                           0\n",
      "roof_type                                 0\n",
      "ground_floor_type                         0\n",
      "other_floor_type                          0\n",
      "position                                  0\n",
      "plan_configuration                        0\n",
      "has_superstructure_adobe_mud              0\n",
      "has_superstructure_mud_mortar_stone       0\n",
      "has_superstructure_stone_flag             0\n",
      "has_superstructure_cement_mortar_stone    0\n",
      "has_superstructure_mud_mortar_brick       0\n",
      "has_superstructure_cement_mortar_brick    0\n",
      "has_superstructure_timber                 0\n",
      "has_superstructure_bamboo                 0\n",
      "has_superstructure_rc_non_engineered      0\n",
      "has_superstructure_rc_engineered          0\n",
      "has_superstructure_other                  0\n",
      "legal_ownership_status                    0\n",
      "count_families                            0\n",
      "has_secondary_use                         0\n",
      "has_secondary_use_agriculture             0\n",
      "has_secondary_use_hotel                   0\n",
      "has_secondary_use_rental                  0\n",
      "has_secondary_use_institution             0\n",
      "has_secondary_use_school                  0\n",
      "has_secondary_use_industry                0\n",
      "has_secondary_use_health_post             0\n",
      "has_secondary_use_gov_office              0\n",
      "has_secondary_use_use_police              0\n",
      "has_secondary_use_other                   0\n",
      "dtype: int64\n",
      "----------------------------\n",
      "\n",
      "\n",
      "----------------------------\n",
      "Unique values in dataset sorted: has_superstructure_mud_mortar_brick            2\n",
      "has_superstructure_cement_mortar_brick         2\n",
      "has_superstructure_timber                      2\n",
      "has_superstructure_bamboo                      2\n",
      "has_superstructure_rc_non_engineered           2\n",
      "has_superstructure_rc_engineered               2\n",
      "has_superstructure_other                       2\n",
      "has_secondary_use                              2\n",
      "has_secondary_use_agriculture                  2\n",
      "has_secondary_use_hotel                        2\n",
      "has_secondary_use_rental                       2\n",
      "has_secondary_use_institution                  2\n",
      "has_secondary_use_school                       2\n",
      "has_secondary_use_industry                     2\n",
      "has_secondary_use_health_post                  2\n",
      "has_secondary_use_gov_office                   2\n",
      "has_secondary_use_use_police                   2\n",
      "has_superstructure_cement_mortar_stone         2\n",
      "has_secondary_use_other                        2\n",
      "has_superstructure_mud_mortar_stone            2\n",
      "has_superstructure_adobe_mud                   2\n",
      "has_superstructure_stone_flag                  2\n",
      "land_surface_condition                         3\n",
      "roof_type                                      3\n",
      "position                                       4\n",
      "other_floor_type                               4\n",
      "legal_ownership_status                         4\n",
      "foundation_type                                5\n",
      "ground_floor_type                              5\n",
      "count_floors_pre_eq                            9\n",
      "plan_configuration                            10\n",
      "count_families                                10\n",
      "height_percentage                             27\n",
      "geo_level_1_id                                31\n",
      "age                                           42\n",
      "area_percentage                               84\n",
      "geo_level_2_id                              1414\n",
      "geo_level_3_id                             11595\n",
      "building_id                               260601\n",
      "dtype: int64\n",
      "----------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260596</th>\n",
       "      <td>688636</td>\n",
       "      <td>25</td>\n",
       "      <td>1335</td>\n",
       "      <td>1621</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260597</th>\n",
       "      <td>669485</td>\n",
       "      <td>17</td>\n",
       "      <td>715</td>\n",
       "      <td>2060</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260598</th>\n",
       "      <td>602512</td>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "      <td>8163</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260599</th>\n",
       "      <td>151409</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>1851</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260600</th>\n",
       "      <td>747594</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>9101</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "260596       688636              25            1335            1621   \n",
       "260597       669485              17             715            2060   \n",
       "260598       602512              17              51            8163   \n",
       "260599       151409              26              39            1851   \n",
       "260600       747594              21               9            9101   \n",
       "\n",
       "       count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "260596                   1   55                6                  3   \n",
       "260597                   2    0                6                  5   \n",
       "260598                   3   55                6                  7   \n",
       "260599                   2   10               14                  6   \n",
       "260600                   3   10                7                  6   \n",
       "\n",
       "       land_surface_condition foundation_type  ...  \\\n",
       "260596                      n               r  ...   \n",
       "260597                      t               r  ...   \n",
       "260598                      t               r  ...   \n",
       "260599                      t               r  ...   \n",
       "260600                      n               r  ...   \n",
       "\n",
       "       has_secondary_use_agriculture has_secondary_use_hotel  \\\n",
       "260596                         False                   False   \n",
       "260597                         False                   False   \n",
       "260598                         False                   False   \n",
       "260599                         False                   False   \n",
       "260600                         False                   False   \n",
       "\n",
       "       has_secondary_use_rental has_secondary_use_institution  \\\n",
       "260596                    False                         False   \n",
       "260597                    False                         False   \n",
       "260598                    False                         False   \n",
       "260599                    False                         False   \n",
       "260600                    False                         False   \n",
       "\n",
       "       has_secondary_use_school  has_secondary_use_industry  \\\n",
       "260596                    False                       False   \n",
       "260597                    False                       False   \n",
       "260598                    False                       False   \n",
       "260599                    False                       False   \n",
       "260600                    False                       False   \n",
       "\n",
       "        has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "260596                          False                         False   \n",
       "260597                          False                         False   \n",
       "260598                          False                         False   \n",
       "260599                          False                         False   \n",
       "260600                          False                         False   \n",
       "\n",
       "        has_secondary_use_use_police  has_secondary_use_other  \n",
       "260596                         False                    False  \n",
       "260597                         False                    False  \n",
       "260598                         False                    False  \n",
       "260599                         False                    False  \n",
       "260600                         False                    False  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_style(f\"shape of data set : {df.shape}\")\n",
    "print_style(f\"dtypes of data set : {df.dtypes}\")\n",
    "print_style(f\"info of data set : {df.info()}\")\n",
    "print_style(f\"Null values in dataset : {df.isnull().sum()}\")\n",
    "print_style(f\"Unique values in dataset sorted: {df.nunique().sort_values()}\")\n",
    "df.head()\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a810d",
   "metadata": {},
   "source": [
    "### Conclusion :\n",
    " - shape : (260601, 39)\n",
    " - no missing elements\n",
    " - types are only int, bool and str\n",
    " - many booleans and categorical data (could be replaced or factorized) :\n",
    "      - Unique values in dataset sorted:\n",
    "      booleans                                       2\n",
    "            superstructure abode (mud, mud mortar stone, stone falge, cement mortar stone, mud mortart brick, cement mortar brick, timber, bamboo, rc (non) engirneered, other)\n",
    "            secondary use (0/1, agriculture, hotel, rental, institution, school, industry, health post, gov office, police, other)\n",
    "      roof_type                                      3\n",
    "      land_surface_condition                         3\n",
    "      legal_ownership_status                         4\n",
    "      other_floor_type                               4\n",
    "      position                                       4\n",
    "      foundation_type                                5\n",
    "      ground_floor_type                              5\n",
    "      count_floors_pre_eq                            9\n",
    "      count_families                                10\n",
    "      plan_configuration                            10\n",
    "      height_percentage                             27\n",
    "      geo_level_1_id                                31\n",
    "      age                                           42\n",
    "      area_percentage                               84\n",
    "      geo_level_2_id                              1414\n",
    "      geo_level_3_id                             11595\n",
    "      building_id                               260601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e32b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def safe_sort_unique(vals):\n",
    "    try:\n",
    "        return sorted(vals, key=lambda x: float(x))\n",
    "    except:\n",
    "        return sorted(vals)\n",
    "\n",
    "def plot_bool(col):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(f\"Distribution of {col.name}\", fontsize=14)\n",
    "\n",
    "    counts = col.value_counts().sort_index()\n",
    "    plt.bar(counts.index.astype(int), counts.values)\n",
    "    plt.xticks([0, 1], ['False', 'True'])\n",
    "    plt.xlabel(col.name)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_categorical(col):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title(f\"{col.name} - Categorical Distribution\", fontsize=14)\n",
    "    \n",
    "    # Get value counts and sort\n",
    "    counts = col.astype(str).value_counts()\n",
    "    order = safe_sort_unique(counts.index)\n",
    "    counts = counts.reindex(order)\n",
    "    \n",
    "    plt.bar(range(len(counts)), counts.values)\n",
    "    plt.xticks(range(len(counts)), counts.index, rotation=45, ha='right')\n",
    "    plt.xlabel(col.name)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_ints(col, log_numeric=[]):\n",
    "    # Remove NaN values\n",
    "    col_clean = col.dropna()\n",
    "    \n",
    "    if len(col_clean) == 0:\n",
    "        print(f\"Warning: {col.name} has no valid data to plot\")\n",
    "        return\n",
    "    \n",
    "    if col.name in log_numeric:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "        fig.suptitle(f\"Distribution of {col.name}\", fontsize=15)\n",
    "\n",
    "        # Linear scale\n",
    "        sns.histplot(col_clean, kde=True, stat=\"density\", ax=axes[0])\n",
    "        axes[0].set_title(f\"{col.name} - Linear Scale\")\n",
    "        axes[0].set_xlabel(col.name)\n",
    "\n",
    "        # Log scale (visual only) - filter out zeros and negatives\n",
    "        col_positive = col_clean[col_clean > 0]\n",
    "        if len(col_positive) > 0:\n",
    "            sns.histplot(col_positive, kde=True, stat=\"density\", ax=axes[1])\n",
    "            axes[1].set_xscale('log')\n",
    "            axes[1].set_title(f\"{col.name} - Log Scale (positive values only)\")\n",
    "            axes[1].set_xlabel(col.name)\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, 'No positive values for log scale', \n",
    "                        ha='center', va='center', transform=axes[1].transAxes)\n",
    "            axes[1].set_title(f\"{col.name} - Log Scale (no data)\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.title(f\"Distribution of {col.name}\", fontsize=14)\n",
    "        sns.histplot(col_clean, kde=True, stat=\"density\")\n",
    "        plt.xlabel(col.name)\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_all_data(df):\n",
    "    LOG_NUMERIC = [\"age\", \"area_percentage\", \"height_percentage\"]\n",
    "\n",
    "    for col_name in df.columns:\n",
    "        col = df[col_name]\n",
    "        col_dtype = col.dtype\n",
    "\n",
    "        # CRITICAL FIX: Check for bool BEFORE integer, because bool is a subtype of int\n",
    "        if pd.api.types.is_bool_dtype(col_dtype):\n",
    "            plot_bool(col)\n",
    "        elif pd.api.types.is_integer_dtype(col_dtype):\n",
    "            plot_ints(col, log_numeric=LOG_NUMERIC)\n",
    "        elif pd.api.types.is_categorical_dtype(col_dtype) or pd.api.types.is_object_dtype(col_dtype):\n",
    "            plot_categorical(col)\n",
    "\n",
    "#plot_all_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fa034",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cd0d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def fix_imbalance(df, dtype, rf_hyperparameters:dict, basic_thresholds:dict, use_thresholds:bool):\n",
    "      ### not all rf_hyperparameters should be used only the relevant ones\n",
    "      ### multiple transformations should be applied : reduction + duplication + ... (all if needed of course)\n",
    "      ### at each step we could either use a formulas of rf_hyperparameters to match a basic threshold (drop_rate, duplicate_rate, imbalance level, ...)\n",
    "      ### we could decide to either use the basic_thresholds or the rf_hyperparameters based on use_thresholds \n",
    "      match dtype:\n",
    "            case \"int64\":\n",
    "                  # call a function\n",
    "                  ...\n",
    "            case \"bool\":\n",
    "                  # call a function\n",
    "                  ...\n",
    "            case \"category\":\n",
    "                  # call a function\n",
    "                  ...\n",
    "      ...\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_rf(df:DataFrame, bool_thresh=0.95, cat_min_freq=0.02, clip_quantile=None):\n",
    "      preprocess_df = pd>DataFrame()\n",
    "      for col in df.columns:\n",
    "            # modify the cols and save them in preprocess_df using the fix_imbalance() function\n",
    "            ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2243217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üå≤ RANDOM FOREST PREPROCESSING\n",
      "======================================================================\n",
      "üìã Input shape: (260601, 39)\n",
      "‚öôÔ∏è  RF Hyperparameters: {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "üéØ Using RF formulas\n",
      "\n",
      "Processing: building_id (dtype: int64)\n",
      "\n",
      "Processing: geo_level_1_id (dtype: int64)\n",
      "\n",
      "Processing: geo_level_2_id (dtype: int64)\n",
      "\n",
      "Processing: geo_level_3_id (dtype: int64)\n",
      "\n",
      "Processing: count_floors_pre_eq (dtype: category)\n",
      "\n",
      "Processing: age (dtype: int64)\n",
      "\n",
      "Processing: area_percentage (dtype: int64)\n",
      "\n",
      "Processing: height_percentage (dtype: int64)\n",
      "\n",
      "Processing: land_surface_condition (dtype: category)\n",
      "\n",
      "Processing: foundation_type (dtype: category)\n",
      "\n",
      "Processing: roof_type (dtype: category)\n",
      "\n",
      "Processing: ground_floor_type (dtype: category)\n",
      "\n",
      "Processing: other_floor_type (dtype: category)\n",
      "\n",
      "Processing: position (dtype: category)\n",
      "\n",
      "Processing: plan_configuration (dtype: category)\n",
      "\n",
      "Processing: has_superstructure_adobe_mud (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_mud_mortar_stone (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_stone_flag (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_cement_mortar_stone (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_mud_mortar_brick (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_cement_mortar_brick (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_timber (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_bamboo (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_rc_non_engineered (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_rc_engineered (dtype: bool)\n",
      "\n",
      "Processing: has_superstructure_other (dtype: bool)\n",
      "\n",
      "Processing: legal_ownership_status (dtype: category)\n",
      "\n",
      "Processing: count_families (dtype: category)\n",
      "\n",
      "Processing: has_secondary_use (dtype: bool)\n",
      "\n",
      "Processing: has_secondary_use_agriculture (dtype: bool)\n",
      "\n",
      "Processing: has_secondary_use_hotel (dtype: bool)\n",
      "\n",
      "Processing: has_secondary_use_rental (dtype: bool)\n",
      "\n",
      "Processing: has_secondary_use_institution (dtype: bool)\n",
      "   ‚ùå DROP: has_secondary_use_institution (max_freq=0.9991 > threshold=0.9990)\n",
      "\n",
      "Processing: has_secondary_use_school (dtype: bool)\n",
      "   ‚ùå DROP: has_secondary_use_school (max_freq=0.9996 > threshold=0.9990)\n",
      "\n",
      "Processing: has_secondary_use_industry (dtype: bool)\n",
      "\n",
      "Processing: has_secondary_use_health_post (dtype: bool)\n",
      "   ‚ùå DROP: has_secondary_use_health_post (max_freq=0.9998 > threshold=0.9990)\n",
      "\n",
      "Processing: has_secondary_use_gov_office (dtype: bool)\n",
      "   ‚ùå DROP: has_secondary_use_gov_office (max_freq=0.9999 > threshold=0.9990)\n",
      "\n",
      "Processing: has_secondary_use_use_police (dtype: bool)\n",
      "   ‚ùå DROP: has_secondary_use_use_police (max_freq=0.9999 > threshold=0.9990)\n",
      "\n",
      "Processing: has_secondary_use_other (dtype: bool)\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Preprocessing complete!\n",
      "üìã Output shape: (260601, 34)\n",
      "üóëÔ∏è  Dropped 5 columns: ['has_secondary_use_institution', 'has_secondary_use_school', 'has_secondary_use_health_post', 'has_secondary_use_gov_office', 'has_secondary_use_use_police']\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
      "C:\\Users\\dongw\\AppData\\Local\\Temp\\ipykernel_27136\\2890813965.py:239: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from typing import Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "      drop thresholds : \n",
    "            bool : 1 - safety_factor * (min_samples_leaf / n_samples) * (1 / max_features) * (1 / np.sqrt(n_estimators))\n",
    "            categorical : (min_samples_split / n_samples) * (1 / max_features) * (1 / np.sqrt(n_estimators))\n",
    "      skew fix to log threshold : \n",
    "            n_samples / (min_samples_leaf * (n_estimators ** 0.25))\n",
    "      consider categorical threshold : \n",
    "            n_unique <= min(20, int(np.sqrt(n_samples) / 10)) where n_unique is the # of appearance of a value\n",
    "      \n",
    "      other functions are just implentations \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def calculate_bool_drop_threshold(n_samples: int, rf_params: dict, safety_factor: float = 1.5) -> float:\n",
    "    \"\"\"\n",
    "    Calculate threshold for dropping imbalanced boolean features.\n",
    "    Drop if: max(p_0, p_1) > threshold\n",
    "    threshold = 1 - safety_factor * (min_samples_leaf / n_samples) * (1 / max_features) * (1 / np.sqrt(n_estimators))\n",
    "    \"\"\"\n",
    "    min_samples_leaf = rf_params.get('min_samples_leaf', 1)\n",
    "    max_features = rf_params.get('max_features', 0.33)  # default to sqrt\n",
    "    n_estimators = rf_params.get('n_estimators', 100)\n",
    "    \n",
    "    # Convert max_features to fraction if it's a string\n",
    "    if isinstance(max_features, str):\n",
    "        if max_features == 'sqrt':\n",
    "            max_features = 0.33\n",
    "        elif max_features == 'log2':\n",
    "            max_features = 0.2\n",
    "        else:\n",
    "            max_features = 1.0\n",
    "    \n",
    "    threshold = 1 - safety_factor * (min_samples_leaf / n_samples) * (1 / max_features) * (1 / np.sqrt(n_estimators))\n",
    "    return min(0.999, max(0.5, threshold))  # Clamp between 0.5 and 0.999\n",
    "\n",
    "def calculate_categorical_merge_threshold(n_samples: int, rf_params: dict) -> float:\n",
    "    \"\"\"\n",
    "    Calculate threshold for merging rare categorical values.\n",
    "    Merge if: frequency < threshold\n",
    "    threshold = (min_samples_split / n_samples) * (1 / max_features) * (1 / np.sqrt(n_estimators))\n",
    "    \"\"\"\n",
    "    min_samples_split = rf_params.get('min_samples_split', 2)\n",
    "    max_features = rf_params.get('max_features', 0.33)\n",
    "    n_estimators = rf_params.get('n_estimators', 100)\n",
    "    \n",
    "    # Convert max_features to fraction\n",
    "    if isinstance(max_features, str):\n",
    "        if max_features == 'sqrt':\n",
    "            max_features = 0.33\n",
    "        elif max_features == 'log2':\n",
    "            max_features = 0.2\n",
    "        else:\n",
    "            max_features = 1.0\n",
    "    \n",
    "    threshold = (min_samples_split / n_samples) * (1 / max_features) * (1 / np.sqrt(n_estimators))\n",
    "    return max(0.0001, min(0.1, threshold))  # Clamp between 0.01% and 10%\n",
    "\n",
    "def calculate_skew_transform_threshold(n_samples: int, rf_params: dict) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculate thresholds for log-transforming skewed numeric features.\n",
    "    Returns: (skew_threshold, range_threshold)\n",
    "    \"\"\"\n",
    "    min_samples_leaf = rf_params.get('min_samples_leaf', 1)\n",
    "    n_estimators = rf_params.get('n_estimators', 100)\n",
    "    \n",
    "    skew_threshold = 3.0  # Standard threshold for high skewness\n",
    "    range_threshold = n_samples / (min_samples_leaf * (n_estimators ** 0.25))\n",
    "    \n",
    "    return skew_threshold, max(100, range_threshold)\n",
    "\n",
    "def should_treat_as_categorical(n_unique: int, n_samples: int) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a small-integer column should be treated as categorical.\n",
    "    \"\"\"\n",
    "    return n_unique <= min(20, int(np.sqrt(n_samples) / 10))\n",
    "\n",
    "def fix_bool_imbalance(col: pd.Series, n_samples: int, rf_params: dict, \n",
    "                       basic_threshold: float, use_formulas: bool) -> Optional[pd.Series]:\n",
    "    \"\"\"\n",
    "    Fix boolean column imbalance by dropping if too imbalanced.\n",
    "    Returns None if column should be dropped.\n",
    "    \"\"\"\n",
    "    value_counts = col.value_counts(normalize=True)\n",
    "    if len(value_counts) == 0:\n",
    "        return None\n",
    "    \n",
    "    max_freq = value_counts.iloc[0]\n",
    "    \n",
    "    # Determine threshold\n",
    "    if use_formulas:\n",
    "        threshold = calculate_bool_drop_threshold(n_samples, rf_params)\n",
    "    else:\n",
    "        threshold = basic_threshold\n",
    "    \n",
    "    # Drop if too imbalanced\n",
    "    if max_freq > threshold:\n",
    "        print(f\"   ‚ùå DROP: {col.name} (max_freq={max_freq:.4f} > threshold={threshold:.4f})\")\n",
    "        return None\n",
    "    \n",
    "    return col\n",
    "\n",
    "def fix_categorical_imbalance(col: pd.Series, n_samples: int, rf_params: dict,\n",
    "                               basic_threshold: float, use_formulas: bool,\n",
    "                               min_categories: int = 10) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fix categorical column by merging rare categories into 'Other'.\n",
    "    \"\"\"\n",
    "    col = col.copy()\n",
    "    n_unique = col.nunique()\n",
    "    \n",
    "    # Don't merge if low cardinality\n",
    "    if n_unique <= min_categories:\n",
    "        return col\n",
    "    \n",
    "    freq = col.value_counts(normalize=True)\n",
    "    \n",
    "    # Determine threshold\n",
    "    if use_formulas:\n",
    "        threshold = calculate_categorical_merge_threshold(n_samples, rf_params)\n",
    "    else:\n",
    "        threshold = basic_threshold\n",
    "    \n",
    "    # Find rare categories\n",
    "    rare_categories = freq[freq < threshold].index.tolist()\n",
    "    \n",
    "    if rare_categories:\n",
    "        col = col.replace(rare_categories, 'Other')\n",
    "        print(f\"   üîß MERGE: {col.name} - merged {len(rare_categories)}/{n_unique} categories (freq < {threshold:.4f})\")\n",
    "    \n",
    "    return col\n",
    "\n",
    "def fix_numeric_skewness(col: pd.Series, n_samples: int, rf_params: dict,\n",
    "                         use_formulas: bool) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fix highly skewed numeric columns with log1p transform.\n",
    "    \"\"\"\n",
    "    col = col.copy()\n",
    "    \n",
    "    # Skip if has negative values\n",
    "    if col.min() < 0:\n",
    "        return col\n",
    "    \n",
    "    # Skip if all zeros or constant\n",
    "    if col.nunique() <= 1:\n",
    "        return col\n",
    "    \n",
    "    # Calculate skewness and range\n",
    "    skew_val = col.skew()\n",
    "    col_min = col.min()\n",
    "    col_max = col.max()\n",
    "    \n",
    "    if col_min == 0:\n",
    "        value_range = col_max\n",
    "    else:\n",
    "        value_range = col_max / col_min\n",
    "    \n",
    "    # Determine thresholds\n",
    "    if use_formulas:\n",
    "        skew_threshold, range_threshold = calculate_skew_transform_threshold(n_samples, rf_params)\n",
    "    else:\n",
    "        skew_threshold = 3.0\n",
    "        range_threshold = 1000\n",
    "    \n",
    "    # Transform if both conditions met\n",
    "    if skew_val > skew_threshold and value_range > range_threshold:\n",
    "        col = np.log1p(col)\n",
    "        print(f\"   üìä LOG-TRANSFORM: {col.name} (skew={skew_val:.2f}, range={value_range:.2f})\")\n",
    "    \n",
    "    return col\n",
    "\n",
    "def fix_small_int_as_categorical(col: pd.Series, n_samples: int, rf_params: dict,\n",
    "                                  basic_threshold: float, use_formulas: bool,\n",
    "                                  min_categories: int = 10) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Treat small-integer columns as categorical and apply categorical preprocessing.\n",
    "    \"\"\"\n",
    "    n_unique = col.nunique()\n",
    "    \n",
    "    # Check if should be treated as categorical\n",
    "    if not should_treat_as_categorical(n_unique, n_samples):\n",
    "        return col\n",
    "    \n",
    "    print(f\"   üîÑ TREAT AS CATEGORICAL: {col.name} ({n_unique} unique values)\")\n",
    "    \n",
    "    # Convert to categorical and apply categorical fix\n",
    "    col_cat = col.astype(str).astype('category')\n",
    "    return fix_categorical_imbalance(col_cat, n_samples, rf_params, basic_threshold, use_formulas, min_categories)\n",
    "\n",
    "def fix_imbalance(col: pd.Series, df_shape: Tuple[int, int], rf_hyperparameters: dict,\n",
    "                  basic_thresholds: dict, use_thresholds: bool) -> Optional[pd.Series]:\n",
    "    \"\"\"\n",
    "    Fix imbalance in a single column based on its dtype.\n",
    "    \n",
    "    Args:\n",
    "        col: pandas Series to preprocess\n",
    "        df_shape: (n_samples, n_features) tuple\n",
    "        rf_hyperparameters: dict with RF params (n_estimators, max_depth, etc.)\n",
    "        basic_thresholds: dict with manual thresholds (bool_thresh, cat_min_freq, etc.)\n",
    "        use_thresholds: if True, use basic_thresholds; if False, use RF formulas\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed column or None if should be dropped\n",
    "    \"\"\"\n",
    "    n_samples = df_shape[0]\n",
    "    dtype_str = str(col.dtype)\n",
    "    \n",
    "    # Boolean columns\n",
    "    if pd.api.types.is_bool_dtype(col):\n",
    "        return fix_bool_imbalance(\n",
    "            col, n_samples, rf_hyperparameters,\n",
    "            basic_thresholds.get('bool_thresh', 0.95),\n",
    "            not use_thresholds  # use_formulas is opposite of use_thresholds\n",
    "        )\n",
    "    \n",
    "    # Integer columns\n",
    "    elif pd.api.types.is_integer_dtype(col):\n",
    "        n_unique = col.nunique()\n",
    "        \n",
    "        # Check if should be treated as categorical\n",
    "        if should_treat_as_categorical(n_unique, n_samples):\n",
    "            return fix_small_int_as_categorical(\n",
    "                col, n_samples, rf_hyperparameters,\n",
    "                basic_thresholds.get('cat_min_freq', 0.02),\n",
    "                not use_thresholds\n",
    "            )\n",
    "        else:\n",
    "            # Apply numeric skewness fix\n",
    "            return fix_numeric_skewness(col, n_samples, rf_hyperparameters, not use_thresholds)\n",
    "    \n",
    "    # Categorical columns\n",
    "    elif pd.api.types.is_categorical_dtype(col) or pd.api.types.is_object_dtype(col):\n",
    "        return fix_categorical_imbalance(\n",
    "            col, n_samples, rf_hyperparameters,\n",
    "            basic_thresholds.get('cat_min_freq', 0.02),\n",
    "            not use_thresholds\n",
    "        )\n",
    "    \n",
    "    # Float columns (numeric)\n",
    "    elif pd.api.types.is_float_dtype(col):\n",
    "        return fix_numeric_skewness(col, n_samples, rf_hyperparameters, not use_thresholds)\n",
    "    \n",
    "    # Unknown dtype - return as is\n",
    "    else:\n",
    "        warnings.warn(f\"Unknown dtype for column {col.name}: {dtype_str}\")\n",
    "        return col\n",
    "\n",
    "def preprocess_rf(df: DataFrame, \n",
    "                  rf_hyperparameters: Optional[dict] = None,\n",
    "                  use_rf_formulas: bool = True,\n",
    "                  bool_thresh: float = 0.95,\n",
    "                  cat_min_freq: float = 0.02,\n",
    "                  min_categories: int = 10) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess dataframe for Random Forest by fixing feature imbalances.\n",
    "    \n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        rf_hyperparameters: RF hyperparameters dict. If None, uses defaults.\n",
    "        use_rf_formulas: If True, calculate thresholds from RF params. If False, use manual thresholds.\n",
    "        bool_thresh: Manual threshold for dropping boolean columns (if use_rf_formulas=False)\n",
    "        cat_min_freq: Manual threshold for merging categories (if use_rf_formulas=False)\n",
    "        min_categories: Don't merge categories if column has fewer than this many unique values\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed dataframe\n",
    "    \"\"\"\n",
    "    # Default RF hyperparameters\n",
    "    if rf_hyperparameters is None:\n",
    "        rf_hyperparameters = {\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': None,\n",
    "            'min_samples_split': 20,\n",
    "            'min_samples_leaf': 10,\n",
    "            'max_features': 'sqrt'\n",
    "        }\n",
    "    \n",
    "    basic_thresholds = {\n",
    "        'bool_thresh': bool_thresh,\n",
    "        'cat_min_freq': cat_min_freq\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"üå≤ RANDOM FOREST PREPROCESSING\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"üìã Input shape: {df.shape}\")\n",
    "    print(f\"‚öôÔ∏è  RF Hyperparameters: {rf_hyperparameters}\")\n",
    "    print(f\"üéØ Using {'RF formulas' if use_rf_formulas else 'manual thresholds'}\")\n",
    "    \n",
    "    if not use_rf_formulas:\n",
    "        print(f\"   - bool_thresh: {bool_thresh}\")\n",
    "        print(f\"   - cat_min_freq: {cat_min_freq}\")\n",
    "    print()\n",
    "    \n",
    "    preprocessed_df = pd.DataFrame()\n",
    "    dropped_cols = []\n",
    "    \n",
    "    for col_name in df.columns:\n",
    "        print(f\"Processing: {col_name} (dtype: {df[col_name].dtype})\")\n",
    "        \n",
    "        result = fix_imbalance(\n",
    "            df[col_name],\n",
    "            df.shape,\n",
    "            rf_hyperparameters,\n",
    "            basic_thresholds,\n",
    "            use_thresholds=not use_rf_formulas\n",
    "        )\n",
    "        \n",
    "        if result is not None:\n",
    "            preprocessed_df[col_name] = result\n",
    "        else:\n",
    "            dropped_cols.append(col_name)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"‚úÖ Preprocessing complete!\")\n",
    "    print(f\"üìã Output shape: {preprocessed_df.shape}\")\n",
    "    print(f\"üóëÔ∏è  Dropped {len(dropped_cols)} columns: {dropped_cols}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return preprocessed_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example with RF formulas (recommended)\n",
    "    rf_params = {\n",
    "        'n_estimators': 1000,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': 'sqrt'\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Using RF formulas\n",
    "    df_processed = preprocess_rf(df, rf_hyperparameters=rf_params, use_rf_formulas=True)\n",
    "    #plot_all_data(df_processed)\n",
    "    # Or using manual thresholds\n",
    "    # df_processed = preprocess_rf(df, use_rf_formulas=False, bool_thresh=0.95, cat_min_freq=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf00507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning...\n",
      "Best Parameters: {'class_weight': None, 'max_depth': 30, 'max_features': 0.5, 'min_samples_leaf': 2, 'n_estimators': 400}\n",
      "Best CV Score: 0.7264\n",
      "\n",
      "[Test Set Evaluation]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.49      0.57      5025\n",
      "           2       0.74      0.85      0.79     29652\n",
      "           3       0.76      0.63      0.69     17444\n",
      "\n",
      "    accuracy                           0.74     52121\n",
      "   macro avg       0.73      0.66      0.68     52121\n",
      "weighted avg       0.74      0.74      0.73     52121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ==========================================\n",
    "# 1. Data Preparation\n",
    "# ==========================================\n",
    "X = df_processed.copy()\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X = df_processed.copy()\n",
    "\n",
    "X[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "y = pd.read_csv(\"train_labels.csv\")[\"damage_grade\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 2. Model Initialization\n",
    "# ==========================================\n",
    "# n_jobs=-1 uses all available CPU cores\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=30,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight=None,\n",
    "    n_estimators=400,\n",
    "    )\n",
    "\n",
    "# ==========================================\n",
    "# 3. Hyperparameter Grid Definition\n",
    "# ==========================================\n",
    "param_grid = {\n",
    "    'n_estimators': [400],              # Number of trees\n",
    "    'max_depth': [30],        # Max depth of trees\n",
    "    'max_features': [ 0.5],        # Features to consider at split\n",
    "    'min_samples_leaf': [2],           # Min samples at leaf node\n",
    "    'class_weight': [None],      # Handling imbalance\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 4. Grid Search Execution\n",
    "# ==========================================\n",
    "gs = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,                 # 5-Fold Cross Validation\n",
    "    scoring='f1_micro',\n",
    "    n_jobs=-1,            # Parallel processing\n",
    ")\n",
    "\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# 5. Results & Evaluation\n",
    "# ==========================================\n",
    "print(f\"Best Parameters: {gs.best_params_}\")\n",
    "print(f\"Best CV Score: {gs.best_score_:.4f}\")\n",
    "\n",
    "# Predict using the best model found\n",
    "best_model = gs.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n[Test Set Evaluation]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#local best CV Score : 0.7264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaac950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0690782\ttest: 1.0687655\tbest: 1.0687655 (0)\ttotal: 7.73ms\tremaining: 1m 17s\n",
      "500:\tlearn: 0.6263108\ttest: 0.6356822\tbest: 0.6356822 (500)\ttotal: 3.79s\tremaining: 1m 11s\n",
      "1000:\tlearn: 0.5916342\ttest: 0.6152120\tbest: 0.6152120 (1000)\ttotal: 7.55s\tremaining: 1m 7s\n",
      "1500:\tlearn: 0.5677646\ttest: 0.6050798\tbest: 0.6050798 (1500)\ttotal: 11.3s\tremaining: 1m 4s\n",
      "2000:\tlearn: 0.5483143\ttest: 0.5995253\tbest: 0.5995253 (2000)\ttotal: 15.1s\tremaining: 1m\n",
      "2500:\tlearn: 0.5310903\ttest: 0.5954759\tbest: 0.5954759 (2500)\ttotal: 18.9s\tremaining: 56.7s\n",
      "3000:\tlearn: 0.5154796\ttest: 0.5928092\tbest: 0.5928092 (3000)\ttotal: 22.8s\tremaining: 53.1s\n",
      "3500:\tlearn: 0.5010075\ttest: 0.5906350\tbest: 0.5906350 (3500)\ttotal: 26.6s\tremaining: 49.3s\n",
      "4000:\tlearn: 0.4871891\ttest: 0.5889651\tbest: 0.5889463 (3995)\ttotal: 30.5s\tremaining: 45.7s\n",
      "4500:\tlearn: 0.4744633\ttest: 0.5880240\tbest: 0.5880178 (4499)\ttotal: 34.4s\tremaining: 42s\n",
      "5000:\tlearn: 0.4625485\ttest: 0.5873229\tbest: 0.5873229 (5000)\ttotal: 38.3s\tremaining: 38.2s\n",
      "bestTest = 0.5872233451\n",
      "bestIteration = 5126\n",
      "Shrink model to first 5127 iterations.\n",
      "Final Model Acc: 0.73982\n",
      "\n",
      "[Test Set Evaluation]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.51      0.58      5025\n",
      "           2       0.74      0.85      0.79     29652\n",
      "           3       0.76      0.62      0.68     17444\n",
      "\n",
      "    accuracy                           0.74     52121\n",
      "   macro avg       0.73      0.66      0.69     52121\n",
      "weighted avg       0.74      0.74      0.73     52121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dongw\\anaconda3\\envs\\study\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ==========================================\n",
    "# 1. Data Preparation\n",
    "# ==========================================\n",
    "X = df_processed.copy() \n",
    "y_raw = pd.read_csv(\"train_labels.csv\")[\"damage_grade\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 2. Model Initialization\n",
    "# ==========================================\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=10000,          \n",
    "    learning_rate=0.05,        \n",
    "    depth=8,                     \n",
    "    devices='0',\n",
    "    one_hot_max_size=10,    \n",
    "    task_type='GPU',           \n",
    "    early_stopping_rounds=100, \n",
    "    verbose=500,\n",
    "    cat_features=categorical_columns,                \n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    cat_features=categorical_columns, \n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Acc: {acc:.5f}\")\n",
    "\n",
    "y_test_org = le.inverse_transform(y_test)\n",
    "y_pred_org = le.inverse_transform(y_pred)\n",
    "\n",
    "print(\"\\n[Test Set Evaluation]\")\n",
    "print(classification_report(y_test_org, y_pred_org))\n",
    "\n",
    "# local CV Score : 0.73982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20031076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0690780\ttotal: 8.59ms\tremaining: 40.8s\n",
      "500:\tlearn: 0.6263109\ttotal: 4.39s\tremaining: 37.3s\n",
      "1000:\tlearn: 0.5916342\ttotal: 8.56s\tremaining: 32.1s\n",
      "1500:\tlearn: 0.5677646\ttotal: 12.7s\tremaining: 27.6s\n",
      "2000:\tlearn: 0.5483144\ttotal: 16.9s\tremaining: 23.2s\n",
      "2500:\tlearn: 0.5310904\ttotal: 21.1s\tremaining: 19s\n",
      "3000:\tlearn: 0.5154796\ttotal: 25.3s\tremaining: 14.8s\n",
      "3500:\tlearn: 0.5010076\ttotal: 29.6s\tremaining: 10.5s\n",
      "4000:\tlearn: 0.4871891\ttotal: 33.8s\tremaining: 6.33s\n",
      "4500:\tlearn: 0.4744632\ttotal: 38.1s\tremaining: 2.1s\n",
      "4749:\tlearn: 0.4684491\ttotal: 40.2s\tremaining: 0us\n",
      "Final Ensemble Score (Micro F1): 0.74388\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ==========================================\n",
    "# 1. Data Preparation\n",
    "# ==========================================\n",
    "X = df_processed.copy() \n",
    "y_raw = pd.read_csv(\"train_labels.csv\")[\"damage_grade\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 2. Non-Categorical Pipeline\n",
    "# ==========================================\n",
    "\n",
    "# For RF Classifier\n",
    "rf_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Ordinal Encoding\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "rf_pipe = Pipeline([\n",
    "    ('preprocessor', rf_preprocessor),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=400, \n",
    "        min_samples_leaf=2,\n",
    "        max_depth=30,\n",
    "        class_weight=None,\n",
    "        max_features=0.5,\n",
    "        random_state=42,\n",
    "        n_jobs=4\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 3. For CatBoost Classifier\n",
    "# ==========================================\n",
    "cb_clf = CatBoostClassifier(\n",
    "    iterations=4750,          \n",
    "    learning_rate=0.05,        \n",
    "    depth=8,                     \n",
    "    devices='0',\n",
    "    one_hot_max_size=10,    \n",
    "    task_type='GPU',           \n",
    "    early_stopping_rounds=100, \n",
    "    verbose=500,\n",
    "    cat_features=categorical_columns,                \n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. VotingClassifier definition\n",
    "# ==========================================\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_pipe),  # name, model pipeline\n",
    "        ('cb', cb_clf)    # name, model pipeline\n",
    "    ],\n",
    "    voting='soft',        # hard : majority voting, soft : probability based voting\n",
    "    weights=[44, 56],\n",
    "    n_jobs=1              \n",
    ")\n",
    "'''\n",
    "params = {\n",
    "    'weights': [\n",
    "        [1, 2],   \n",
    "    ]\n",
    "}\n",
    "\n",
    "grid_vote = GridSearchCV(\n",
    "    estimator=voting_clf,\n",
    "    param_grid=params,\n",
    "    cv=2,\n",
    "    scoring='f1_micro',\n",
    "    n_jobs=1,  \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"Ensemble Model Training with VotingClassifier...\")\n",
    "grid_vote.fit(X_train, y_train)\n",
    "best_model = grid_vote.best_estimator_\n",
    "\n",
    "\n",
    "print(f\"Best Weights: {grid_vote.best_params_}\")\n",
    "print(f\"Best Ensemble Score: {grid_vote.best_score_:.4f}\")\n",
    "\n",
    "'''\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. Results\n",
    "# ==========================================\n",
    "\n",
    "final_model = voting_clf\n",
    "y_pred = final_model.predict(X_test)\n",
    "final_score = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"Final Ensemble Score (Micro F1): {final_score:.5f}\")\n",
    "\n",
    "#local CV Score : 0.74388"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
